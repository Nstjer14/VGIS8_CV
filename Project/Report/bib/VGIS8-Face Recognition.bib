Automatically generated by Mendeley Desktop 1.17.13
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{lfw2007,
abstract = {Face recognition has benefitted greatly from the many databases that have been produced to study it. Most of these databases have been created under controlled conditions to facilitate the study of specific parameters on the face recognition problem. These parameters include such variables as position, pose, lighting, expression, background, camera quality, occlusion, age, and gender. While there are many applications for face recognition technol- ogy in which one can control the parameters of image acquisition, there are also many applications in which the practitioner has little or no control over such parameters. This database is provided as an aid in studying the latter, unconstrained, face recognition problem. The database represents an initial attempt to provide a set of labeled face photographs spanning the range of conditions typically encountered by people in their everyday lives. The database exhibits natural variability in pose, lighting, focus, resolution, facial expression, age, gender, race, accessories, make-up, occlusions, background, and photographic quality. Despite this variability, the images in the database are presented in a simple and consistent format for maximum ease of use. In addition to describing the details of the database and its acquisition, we provide specific experimental paradigms for which the database is suitable. This is done in an effort to make research performed with the database as consistent and comparable as possible.},
author = {Huang, Gary B and Ramesh, Manu and Berg, Tamara and Learned-Miller, Erik},
doi = {10.1.1.122.8268},
file = {::},
isbn = {9781628414844},
issn = {1996756X},
journal = {University of Massachusetts Amherst Technical Report},
pages = {07--49},
title = {{Labeled faces in the wild: A database for studying face recognition in unconstrained environments}},
url = {http://vis-www.cs.umass.edu/lfw/lfw.pdf},
volume = {1},
year = {2007}
}
@article{Simonyan2015,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
doi = {10.1016/j.infsof.2008.09.005},
eprint = {1409.1556},
file = {::},
isbn = {9781450341448},
issn = {09505849},
journal = {International Conference on Learning Representations (ICRL)},
month = {sep},
pages = {1--14},
pmid = {16873662},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {http://arxiv.org/abs/1409.1556},
year = {2015}
}
@article{Crossdata2018,
abstract = {In this paper we study face recognition using convolutional neural network. First, we introduced the basic CNN neural network architecture. Second, we modify the traditional neural network and adapt it to another database by fine tuning its parameters. Third, the network architecture is extended to the cross database problem. The CNN is first trained on a large dataset and then tested on another. Experimental results show that the proposed algorithm is suitable for building various real world applications.},
author = {Guo, Mei and Xiao, Min and Gong, Deliang},
doi = {10.1007/978-3-319-69096-4_54},
file = {:C$\backslash$:/Users/Shaggy/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo, Xiao, Gong - Unknown - Face Recognition Using Deep Convolutional Neural Network in Cross-Database Study.pdf:pdf},
journal = {Advances in Intelligent Systems and Computing},
keywords = {Deep neural network {\'{A}},Face recognition {\'{A}},Image processing},
title = {{Face Recognition Using Deep Convolutional Neural Network in Cross-Database Study}},
url = {https://link-springer-com.zorac.aub.aau.dk/content/pdf/10.1007{\%}2F978-3-319-69096-4{\_}54.pdf},
year = {2017}
}
@inproceedings{Sun2014,
abstract = {The key challenge of face recognition is to develop effective feature representations for reducing intra-personal variations while enlarging inter-personal differences. In this paper, we show that it can be well solved with deep learning and using both face identification and verification signals as supervision. The Deep IDentification-verification features (DeepID2) are learned with carefully designed deep convolutional networks. The face identification task increases the inter-personal variations by drawing DeepID2 extracted from different identities apart, while the face verification task reduces the intra-personal variations by pulling DeepID2 extracted from the same identity together, both of which are essential to face recognition. The learned DeepID2 features can be well generalized to new identities unseen in the training data. On the challenging LFW dataset, 99.15{\%} face verification accuracy is achieved. Compared with the best deep learning result on LFW, the error rate has been significantly reduced by 67{\%}.},
archivePrefix = {arXiv},
arxivId = {1406.4773},
author = {Sun, Yi and Wang, Xiaogang and Tang, Xiaoou},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.244},
eprint = {1406.4773},
file = {::},
isbn = {9781479951178},
issn = {10636919},
keywords = {deep learning,face verification},
pages = {1891--1898},
pmid = {21808091},
title = {{Deep Learning Face Representation by Joint Identification-Verification}},
url = {https://arxiv.org/pdf/1406.4773.pdf http://arxiv.org/abs/1406.4773},
year = {2014}
}
@article{sun2015,
abstract = {The state-of-the-art of face recognition has been significantly advanced by the emergence of deep learning. Very deep neural networks recently achieved great success on general object recognition because of their superb learning capacity. This motivates us to investigate their effectiveness on face recognition. This paper proposes two very deep neural network architectures, referred to as DeepID3, for face recognition. These two architectures are rebuilt from stacked convolution and inception layers proposed in VGG net and GoogLeNet to make them suitable to face recognition. Joint face identification-verification supervisory signals are added to both intermediate and final feature extraction layers during training. An ensemble of the proposed two architectures achieves 99.53{\%} LFW face verification accuracy and 96.0{\%} LFW rank-1 face identification accuracy, respectively. A further discussion of LFW face verification result is given in the end.},
archivePrefix = {arXiv},
arxivId = {1502.00873},
author = {Sun, Yi and Liang, Ding and Wang, Xiaogang and Tang, Xiaoou},
eprint = {1502.00873},
file = {::},
title = {{DeepID3: Face Recognition with Very Deep Neural Networks}},
url = {https://arxiv.org/pdf/1502.00873.pdf http://arxiv.org/abs/1502.00873},
year = {2015}
}
@inproceedings{Ghazi2016,
abstract = {Deep learning based approaches have been dominating the face recognition field due to the significant performance improvement they have provided on the challenging wild datasets. These approaches have been extensively tested on such unconstrained datasets, on the Labeled Faces in the Wild and YouTube Faces, to name a few. However, their capability to handle individual appearance variations caused by factors such as head pose, illumination, occlusion, and misalignment has not been thoroughly assessed till now. In this paper, we present a comprehensive study to evaluate the performance of deep learning based face representation under several conditions including the varying head pose angles, upper and lower face occlusion, changing illumination of different strengths, and misalignment due to erroneous facial feature localization. Two successful and publicly available deep learning models, namely VGG-Face and Lightened CNN have been utilized to extract face representations. The obtained results show that although deep learning provides a powerful representation for face recognition, it can still benefit from preprocessing, for example, for pose and illumination normalization in order to achieve better performance under various conditions. Particularly, if these variations are not included in the dataset used to train the deep learning model, the role of preprocessing becomes more crucial. Experimental results also show that deep learning based representation is robust to misalignment and can tolerate facial feature localization errors up to 10{\%} of the interocular distance.},
author = {Ghazi, Mostafa Mehdipour and Ekenel, Hazim Kemal},
booktitle = {2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)},
doi = {10.1109/CVPRW.2016.20},
file = {::},
isbn = {978-1-5090-1437-8},
month = {jun},
pages = {102--109},
publisher = {IEEE},
title = {{A Comprehensive Analysis of Deep Learning Based Representation for Face Recognition}},
url = {http://ieeexplore.ieee.org/document/7789510/},
year = {2016}
}
@book{Wechsler2007,
abstract = {One of the grand challenges for computational intelligence and biometrics is to understand how people process and recognize faces and to develop automated and reliable face recognition systems. Biometrics has become the major component in the complex decision making process associated with security applications. The face detection and authentication challenges addressed include cluttered environments, image variability, occlusion and disguise, and temporal changes all within open set recognition. Reliable Face Recognition Methods: System Design, Implementation and Evaluation comprehensively explores the face recognition problem while drawing inspiration from complementary disciplines such as neurosciences, statistics, signal and image processing, computer vision, and machine learning and pattern recognition. This book also examines the evolution of face recognition research and explores promising new avenues for research and development. Reliable Face Recognition Methods: System Design, Implementation and Evaluation benefits graduate-level students, researchers, and practitioners, as well as government and industry decision makers in the security arena. Ruud Bolle (IBM): "Harry Wechsler's monograph provides a thorough, up-to-date, and in-depth overview of the many advances in the area of face recognition. gives an excellent overview of the issues related to security and privacy when it comes to automated biometrics. In summary, this book has the potential to become a classic. Harry Wechsler is to be commended for undertaking the monumental task of writing this book." John Daugman (Cambridge University, UK): "The book looks excellent. The topic is timely, and the perspective-multi-disciplinary, measured, and objective - is much needed and welcome. I believe that Wechsler's latest book will make a valued contribution to this important field and will become a standard." David Zhang (Hong Kong Polytechnic University, China): "From a system view, this book shows an excellent arrangement, from data collection to face recognition, as well as system performance evaluation and error analysis. This book can serve both as an interdisciplinary text and a research reference. Each chapter provides the background and impetus for understanding the problems discussed." Stan Li (Chinese Academy of Sciences, China): "The book treats the subject of face recognition in a fairly systematic way. The book covers most relevant topics in face recognition, in a well organized way. The information is also useful for experts. The manuscript is easy to read." Tom Huang (University of Illinois, USA): "Harry Wechsler is without doubt one of the leading authorities in face recognition and related topics. We have recently seen a number of excellent edited books on Face Recognition. However, Wechsler's book is the first unified treatment of this important subject. In my opinion, Wechsler is one of only a handful of people in the world who could write such a comprehensive, unified, informative, perceptive, and authoritative book on Face Recognition. Harry Wechsler so far, is the only one of this handful who took the time and effort to realize such a project. The book certainly will have a great positive impact on the biometrics research community. But also, because it looks at Face Recognition from different perspectives, it will be welcomed by non-experts." {\textcopyright} 2007 Springer Science+Business Media, LLC. All rights reserved.},
address = {Boston, MA},
author = {Wechsler, Harry},
booktitle = {Reliable Face Recognition Methods: System Design, Impementation and Evaluation},
doi = {10.1007/978-0-387-38464-1},
file = {::},
isbn = {038722372X},
pages = {1--329},
publisher = {Springer US},
title = {{Reliable face recognition methods: System design, implementation and evaluation}},
url = {http://link.springer.com/10.1007/978-0-387-38464-1 https://link-springer-com.zorac.aub.aau.dk/book/10.1007{\%}2F978-0-387-38464-1{\#}about},
year = {2007}
}
@article{Krizhevsky2017a,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%}, respectively, which is considerably better than the previous state-of-the-art. The neural network, which has 60 million parameters and 650,000 neurons, con-sists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolution operation. To reduce overfitting in the fully connected layers we employed a recently developed reg-ularization method called " dropout " that proved to be very effective. We also entered a variant of this model in the ILSVRC-2012 competition and achieved a winning top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the sec-ond-best entry. 1. PROLOGUE Four years ago, a paper by Yann LeCun and his collaborators was rejected by the leading computer vision conference on the grounds that it used neural networks and therefore pro-vided no insight into how to design a vision system. At the time, most computer vision researchers believed that a vision system needed to be carefully hand-designed using a detailed understanding of the nature of the task. They assumed that the task of classifying objects in natural images would never be solved by simply presenting examples of images and the names of the objects they contained to a neural network that acquired all of its knowledge from this training data. What many in the vision research community failed to appreciate was that methods that require careful hand-engi-neering by a programmer who understands the domain do not scale as well as methods that replace the programmer with a powerful general-purpose learning procedure. With enough computation and enough data, learning beats pro-gramming for complicated tasks that require the integration of many different, noisy cues. Four years ago, while we were at the University of Toronto, our deep neural network called SuperVision almost halved the error rate for recognizing objects in natural images and triggered an overdue paradigm shift in computer vision. Figure 4 shows some examples of what SuperVision can do. SuperVision evolved from the multilayer neural networks that were widely investigated in the 1980s. These networks used multiple layers of feature detectors that were all learned from the training data. Neuroscientists and psychologists had hypothesized that a hierarchy of such feature detectors would provide a robust way to recognize objects but they had no idea how such a hierarchy could be learned. There was great excite-ment in the 1980s because several different research groups discovered that multiple layers of feature detectors could be trained efficiently using a relatively straight-forward algorithm called backpropagation},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
doi = {10.1145/3065386},
file = {::},
journal = {COMMUNICATIONS OF THE ACM},
number = {6},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
url = {http://delivery.acm.org/10.1145/3070000/3065386/p84-krizhevsky.pdf?ip=130.225.198.196{\&}id=3065386{\&}acc=OA{\&}key=36332CD97FA87885.1DDFD8390336D738.4D4702B0C3E38B35.5945DC2EABF3343C{\&}{\_}{\_}acm{\_}{\_}=1518530104{\_}1e0b97ec1deaadc1937d34c07a1392ac},
volume = {60},
year = {2017}
}
@article{Hu2015,
abstract = {Deep learning, in particular Convolutional Neural Network (CNN), has achieved promising results in face recognition recently. However, it remains an open question: why CNNs work well and how to design a 'good' architecture. The existing works tend to focus on reporting CNN architectures that work well for face recognition rather than investigate the reason. In this work, we conduct an extensive evaluation of CNN-based face recognition systems (CNN-FRS) on a common ground to make our work easily reproducible. Specifically, we use public database LFW (Labeled Faces in the Wild) to train CNNs, unlike most existing CNNs trained on private databases. We propose three CNN architectures which are the first reported architectures trained using LFW data. This paper quantitatively compares the architectures of CNNs and evaluate the effect of different implementation choices. We identify several useful properties of CNN-FRS. For instance, the dimensionality of the learned features can be significantly reduced without adverse effect on face recognition accuracy. In addition, traditional metric learning method exploiting CNN-learned features is evaluated. Experiments show two crucial factors to good CNN-FRS performance are the fusion of multiple CNNs and metric learning. To make our work reproducible, source code and models will be made publicly available.},
archivePrefix = {arXiv},
arxivId = {1504.02351},
author = {Hu, Guosheng and Yang, Yongxin and Yi, Dong and Kittler, Josef and Christmas, William and Li, Stan Z. and Hospedales, Timothy},
doi = {10.1109/ICCVW.2015.58},
eprint = {1504.02351},
file = {::},
isbn = {9780769557205},
issn = {15505499},
journal = {2015 IEEE International Conference on Computer Vision Workshop (ICCVW)},
month = {dec},
pages = {384--392},
publisher = {IEEE},
title = {{When Face Recognition Meets with Deep Learning: an Evaluation of Convolutional Neural Networks for Face Recognition}},
url = {http://ieeexplore.ieee.org/document/7406407/ http://arxiv.org/abs/1504.02351},
year = {2015}
}
@article{Kaur2016a,
abstract = {Face recognition is a type of biometric software application by using which, we can analyzing, identifying or verifying digital image of the person by using the feature of the face of the person that are unique characteristics of each person. These characteristics may be physical or behavioral. The physiological characteristics as like finger print, iris scan, or face etc and behavior characteristics as like hand-writing, voice, key stroke etc. Face recognition is very useful in many areas such as military, airports, universities, ATM, and banks etc, used for the security purposes. There are many techniques or algorithms that are used features extraction in face recognition. This paper make a review of some of those methods which are used for the face recognition that are Principal Component Analysis (PCA), Back Propagation Neural Networks (BPNN), Genetic Algorithm, and LDA, SVM, Independent Component Analysis(ICA). Each method has different -2 functions that are used for the face recognition. Dimensionality is reduced by using the Eigen face approach or PCA, LDA to extract the features from images. Genetic Algorithm is based on feature selection and Back propagation Neural Network (BPNN) is used for the classification of face images.},
author = {Kaur, Gurpreet and Kanwal, Navdeep},
file = {:C$\backslash$:/Users/Shaggy/Desktop/Iris Articles/A comparative review of various approaches for feature extraction in face recognition.pdf:pdf},
isbn = {9789380544212},
journal = {International Conference on Computing for Sustainable Global Development (INDIACom)},
keywords = {BPNN,Face recognition,Features extraction,LDA,PCA},
pages = {2705--2710},
title = {{A comparative review of various approaches for feature extraction in face recognition}},
url = {http://ieeexplore.ieee.org/document/7724754/},
year = {2016}
}
@inproceedings{deepID2014,
abstract = {The key challenge of face recognition is to develop effective feature representations for reducing intra-personal variations while enlarging inter-personal differences. In this paper, we show that it can be well solved with deep learning and using both face identification and verification signals as supervision. The Deep IDentification-verification features (DeepID2) are learned with carefully designed deep convolutional networks. The face identification task increases the inter-personal variations by drawing DeepID2 extracted from different identities apart, while the face verification task reduces the intra-personal variations by pulling DeepID2 extracted from the same identity together, both of which are essential to face recognition. The learned DeepID2 features can be well generalized to new identities unseen in the training data. On the challenging LFW dataset, 99.15{\%} face verification accuracy is achieved. Compared with the best deep learning result on LFW, the error rate has been significantly reduced by 67{\%}.},
archivePrefix = {arXiv},
arxivId = {1406.4773},
author = {Sun, Yi and Wang, Xiaogang and Tang, Xiaoou},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2014.244},
eprint = {1406.4773},
file = {::},
isbn = {9781479951178},
issn = {10636919},
keywords = {deep learning,face verification},
pages = {1891--1898},
pmid = {21808091},
title = {{Deep learning face representation from predicting 10,000 classes}},
url = {http://mmlab.ie.cuhk.edu.hk/pdf/YiSun{\_}CVPR14.pdf},
year = {2014}
}
